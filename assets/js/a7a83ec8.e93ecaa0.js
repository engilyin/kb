"use strict";(self.webpackChunkalex_ilin_kb=self.webpackChunkalex_ilin_kb||[]).push([[8077],{6909:(e,n,i)=>{i.r(n),i.d(n,{assets:()=>a,contentTitle:()=>s,default:()=>h,frontMatter:()=>o,metadata:()=>r,toc:()=>c});const r=JSON.parse('{"id":"Job/TechInterview/Java/core/garbage-collection","title":"garbage-collection","description":"Garbage Collection","source":"@site/docs/Job/TechInterview/Java/core/garbage-collection.md","sourceDirName":"Job/TechInterview/Java/core","slug":"/Job/TechInterview/Java/core/garbage-collection","permalink":"/kb/Job/TechInterview/Java/core/garbage-collection","draft":false,"unlisted":false,"editUrl":"https://github.com/engilyin/kb/docs/Job/TechInterview/Java/core/garbage-collection.md","tags":[],"version":"current","lastUpdatedAt":1727972934000,"frontMatter":{},"sidebar":"defaultSidebar","previous":{"title":"core-java","permalink":"/kb/Job/TechInterview/Java/core/core-java"},"next":{"title":"java-8","permalink":"/kb/Job/TechInterview/Java/core/java-8"}}');var l=i(4848),t=i(8453);const o={},s=void 0,a={},c=[{value:"Garbage Collection",id:"garbage-collection",level:2},{value:"Resources",id:"resources",level:3},{value:"Quick Glance",id:"quick-glance",level:3},{value:"Concepts",id:"concepts",level:3},{value:"Trade offs",id:"trade-offs",level:3},{value:"Use cases",id:"use-cases",level:3},{value:"Tweaks",id:"tweaks",level:3},{value:"Object lifetimes",id:"object-lifetimes",level:3},{value:"Stop the World Events",id:"stop-the-world-events",level:3},{value:"Heap organization in HotSpot",id:"heap-organization-in-hotspot",level:3},{value:"Object allocation",id:"object-allocation",level:3},{value:"Minor Collection",id:"minor-collection",level:3},{value:"Marking Live Objects",id:"marking-live-objects",level:3},{value:"Major Collection",id:"major-collection",level:3},{value:"Serial Collector",id:"serial-collector",level:3},{value:"Parallel Collector",id:"parallel-collector",level:3},{value:"Concurrent Mark and Sweep",id:"concurrent-mark-and-sweep",level:3},{value:"G1 Garbage First",id:"g1-garbage-first",level:3},{value:"Shenandoah",id:"shenandoah",level:3},{value:"Other pauses not related to GC",id:"other-pauses-not-related-to-gc",level:3}];function d(e){const n={a:"a",h2:"h2",h3:"h3",li:"li",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,t.R)(),...e.components};return(0,l.jsxs)(l.Fragment,{children:[(0,l.jsx)(n.h2,{id:"garbage-collection",children:"Garbage Collection"}),"\n",(0,l.jsx)(n.h3,{id:"resources",children:"Resources"}),"\n",(0,l.jsxs)(n.ul,{children:["\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.a,{href:"http://mechanical-sympathy.blogspot.in/2013/07/java-garbage-collection-distilled.html",children:"GC Overview by Martin Thompson"})," - Highly recommended"]}),"\n",(0,l.jsx)(n.li,{children:(0,l.jsx)(n.a,{href:"https://plumbr.eu/handbook/garbage-collection-algorithms-implementations",children:"Detailed overview of all GC collectors"})}),"\n",(0,l.jsx)(n.li,{children:(0,l.jsx)(n.a,{href:"https://blog.plan99.net/modern-garbage-collection-911ef4f8bd8e#.qcnv033nr",children:"Modern Garbage Collection (GC Trade-offs)"})}),"\n",(0,l.jsx)(n.li,{children:(0,l.jsx)(n.a,{href:"https://www.youtube.com/watch?v=Gee7QfoY8ys",children:"Internals of G1 collector"})}),"\n",(0,l.jsx)(n.li,{children:(0,l.jsx)(n.a,{href:"https://www.youtube.com/watch?v=N0JTvyCxiv8",children:"Overview of Shenondoah collector"})}),"\n"]}),"\n",(0,l.jsx)(n.h3,{id:"quick-glance",children:"Quick Glance"}),"\n",(0,l.jsxs)(n.table,{children:[(0,l.jsx)(n.thead,{children:(0,l.jsxs)(n.tr,{children:[(0,l.jsx)(n.th,{children:"Collector"}),(0,l.jsx)(n.th,{children:"Pros"}),(0,l.jsx)(n.th,{children:"Cons"}),(0,l.jsx)(n.th,{children:"Use-Case"})]})}),(0,l.jsxs)(n.tbody,{children:[(0,l.jsxs)(n.tr,{children:[(0,l.jsx)(n.td,{children:"Serial"}),(0,l.jsxs)(n.td,{children:["Fast promotion and minor GC (Bump the pointer)",(0,l.jsx)("br",{}),"Smallest footprint"]}),(0,l.jsx)(n.td,{children:"Single Thread"}),(0,l.jsxs)(n.td,{children:["Limited memory (embedded).",(0,l.jsx)("br",{})," CPU running lot of JVMs (helps limit GC impact other JVMs)"]})]}),(0,l.jsxs)(n.tr,{children:[(0,l.jsx)(n.td,{children:"Parallel"}),(0,l.jsxs)(n.td,{children:["Fast promotion and minor GC (Bump the pointer)",(0,l.jsx)("br",{}),"Higher Throughput (doesn't run with application)"]}),(0,l.jsx)(n.td,{children:"High worst-case latency (due to compaction)"}),(0,l.jsx)(n.td,{children:"Batch applications"})]}),(0,l.jsxs)(n.tr,{children:[(0,l.jsx)(n.td,{children:"CMS"}),(0,l.jsxs)(n.td,{children:["Low STW pauses (Concurrent mark).",(0,l.jsx)("br",{}),"Low worst case latency."]}),(0,l.jsxs)(n.td,{children:["Slow promotion & Minor GC (free lists)",(0,l.jsx)("br",{}),"Reduced throughput",(0,l.jsx)("br",{}),"Higher footprint."]}),(0,l.jsx)(n.td,{children:"General applications"})]}),(0,l.jsxs)(n.tr,{children:[(0,l.jsx)(n.td,{children:"G1"}),(0,l.jsxs)(n.td,{children:["Incremental collection",(0,l.jsx)("br",{}),"Lower worst case latency",(0,l.jsx)("br",{}),"Relatively faster promotion (no free lists) ",(0,l.jsx)("br",{}),"More throughput (no compaction)"]}),(0,l.jsx)(n.td,{children:"Higher footprint"}),(0,l.jsxs)(n.td,{children:["Predictable/Target latency applications.",(0,l.jsx)("br",{}),"Large heaps"]})]}),(0,l.jsxs)(n.tr,{children:[(0,l.jsx)(n.td,{children:"Shenondoah"}),(0,l.jsx)(n.td,{children:"Lower latency"}),(0,l.jsx)(n.td,{children:"Higher footprint"}),(0,l.jsxs)(n.td,{children:["Even lower latency",(0,l.jsx)("br",{})," Much Larger heaps"]})]})]})]}),"\n",(0,l.jsx)(n.h3,{id:"concepts",children:"Concepts"}),"\n",(0,l.jsxs)(n.ul,{children:["\n",(0,l.jsx)(n.li,{children:"Throughput - Percentage of time application runs vs GC"}),"\n",(0,l.jsx)(n.li,{children:"Latency - Amount of pause time for application waiting for GC to complete"}),"\n",(0,l.jsx)(n.li,{children:"Memory - Amount of memory used to store the objects aka heap (along with GC related data structures)"}),"\n"]}),"\n",(0,l.jsx)(n.h3,{id:"trade-offs",children:"Trade offs"}),"\n",(0,l.jsxs)(n.ul,{children:["\n",(0,l.jsx)(n.li,{children:"If memory is less, throughput is less, because JVM has to constantly do GC"}),"\n",(0,l.jsx)(n.li,{children:"If memory is more, latency is high, because JVM has to sweep huge space to do GC"}),"\n"]}),"\n",(0,l.jsx)(n.h3,{id:"use-cases",children:"Use cases"}),"\n",(0,l.jsxs)(n.ul,{children:["\n",(0,l.jsx)(n.li,{children:"For trading applications, deterministic (more average) latency is better than sudden spikes (increased worst case latency)."}),"\n",(0,l.jsx)(n.li,{children:"For batch applications, it might be ok for increase worst case latency, if it helps gain more throughput"}),"\n"]}),"\n",(0,l.jsx)(n.h3,{id:"tweaks",children:"Tweaks"}),"\n",(0,l.jsxs)(n.ul,{children:["\n",(0,l.jsx)(n.li,{children:"To large extent, more memory for GC helps in increasing throughput"}),"\n",(0,l.jsx)(n.li,{children:"Worst case latency can be reduced by keeping heap size small (& live set small)"}),"\n",(0,l.jsx)(n.li,{children:"Frequency of GC can be reduced by managing heap & generation sizes"}),"\n",(0,l.jsx)(n.li,{children:"Frequency of large pauses can be reduced by running GC with application, sometimes at cost of throughput (because it runs longer due to 2 STW pauses, and one thread is used by GC which could've been used by application)."}),"\n"]}),"\n",(0,l.jsx)(n.h3,{id:"object-lifetimes",children:"Object lifetimes"}),"\n",(0,l.jsxs)(n.ul,{children:["\n",(0,l.jsx)(n.li,{children:"Infant mortality / Weak generational hypothesis - Most objects die young."}),"\n",(0,l.jsx)(n.li,{children:"Thus, generational GC algorithms provide magnitude-of-order better throughput."}),"\n",(0,l.jsx)(n.li,{children:"How? Region with newly allocated object is sparse for live objects, they can be quickly copied over and region can be wiped entirely."}),"\n",(0,l.jsx)(n.li,{children:"If application keeps allocating objects that live too long. The generational split becomes useless, and GC takes long time. Because old generation is too big (& not so sparse)."}),"\n",(0,l.jsx)(n.li,{children:"Lifetime of object is recorded by JVM as number of GC cycles survived."}),"\n"]}),"\n",(0,l.jsx)(n.h3,{id:"stop-the-world-events",children:"Stop the World Events"}),"\n",(0,l.jsxs)(n.ul,{children:["\n",(0,l.jsx)(n.li,{children:"Collectors need application execution to stop for practical reasons."}),"\n",(0,l.jsx)(n.li,{children:"Threads are signalled to stop. Threads stop when they reach safe points of execution."}),"\n",(0,l.jsx)(n.li,{children:"If thread is busy (copying large array, cloning a large object), it might be few milliseconds till this point."}),"\n",(0,l.jsx)(n.li,{children:"\u2011XX:+PrintGCApplicationStoppedTime this flag is used to print the time taken to reach safe point."}),"\n",(0,l.jsx)(n.li,{children:"Once GC STW event is over, all threads are free to resume. An application with large number of threads can suffer scheduling pressure. It might be more efficient to use different collector then."}),"\n"]}),"\n",(0,l.jsx)(n.h3,{id:"heap-organization-in-hotspot",children:"Heap organization in HotSpot"}),"\n",(0,l.jsxs)(n.ul,{children:["\n",(0,l.jsx)(n.li,{children:"Heap is split in Young and Old (Tenured) generation"}),"\n",(0,l.jsx)(n.li,{children:"Young generation is split in - Eden and Survivor (1,2) spaces"}),"\n",(0,l.jsx)(n.li,{children:"PermGen is used to store effectively immortal objects (Classes, static strings etc)."}),"\n",(0,l.jsx)(n.li,{children:"In Java 7, interned Strings were removed from PermGen."}),"\n",(0,l.jsx)(n.li,{children:"In Java 8, PermGen space itself is replaced by MetaSpace."}),"\n"]}),"\n",(0,l.jsx)(n.h3,{id:"object-allocation",children:"Object allocation"}),"\n",(0,l.jsxs)(n.ul,{children:["\n",(0,l.jsx)(n.li,{children:"Each thread is assigned TLAB (Thread Local Allocation Buffer) to allocate new objects."}),"\n",(0,l.jsx)(n.li,{children:"Since there is no conflict between threads, object allocation is just a bump-the-pointer, and is faster than MALLOC in C. Roughly 10 machine instructions."}),"\n",(0,l.jsx)(n.li,{children:"When TLAB is exhausted new TLAB is requested from Eden. If Eden is filled, Minor GC is triggered."}),"\n",(0,l.jsx)(n.li,{children:"If a large object (size greater than TLAB) is to be allocated, it is done directly in Eden or Old Generation."}),"\n",(0,l.jsxs)(n.li,{children:["-XX",":PretenureSizeThreshold","=<n> If this is smaller than TLAB, then small objects are still allocated in TLAB itself, not in Old generation."]}),"\n"]}),"\n",(0,l.jsx)(n.h3,{id:"minor-collection",children:"Minor Collection"}),"\n",(0,l.jsxs)(n.ul,{children:["\n",(0,l.jsx)(n.li,{children:"Called when Eden is full."}),"\n",(0,l.jsx)(n.li,{children:"Live objects are moved to one of the survivor spaces."}),"\n",(0,l.jsxs)(n.li,{children:["If survivor space is full or object has live too long (XX",":MaxTenuringThreshold","=<n>) it is moved to tenured generation."]}),"\n",(0,l.jsx)(n.li,{children:"Major cost of minor collection is in copying live objects to survivor / old generation. Thus, overall cost depends on number of objects to be copied not the size of Eden."}),"\n",(0,l.jsx)(n.li,{children:"Thus, if new generation size is doubled, total minor GC time is almost halved (thus increasing the throughput). Assuming number of live objects remain constant."}),"\n",(0,l.jsx)(n.li,{children:"Minor collections are STW events. This is becoming an issue as heaps are getting larger, with more and more live objects."}),"\n",(0,l.jsx)(n.li,{children:"This algorithm is called mark-and-copy"}),"\n"]}),"\n",(0,l.jsx)(n.h3,{id:"marking-live-objects",children:"Marking Live Objects"}),"\n",(0,l.jsxs)(n.ul,{children:["\n",(0,l.jsx)(n.li,{children:"All objects in graph starting from GC Roots"}),"\n",(0,l.jsx)(n.li,{children:"GC roots = references from application, JVM internal static fields and thread stack-frames"}),"\n",(0,l.jsx)(n.li,{children:"References from old generation to young generation (aka cross generational references) are also tracked"}),"\n",(0,l.jsx)(n.li,{children:"Card tables are used for this. Card tables are array of bytes. Each byte represents 512 bytes of old gen. If byte is set, it means corresponding 512 bytes of old gen has reference to young gen objects."}),"\n",(0,l.jsx)(n.li,{children:"During minor collection, all such cards are checked, then all those 512 byte regions are checked for references. Thus, minor collection latency also depends on number of old gen to young gen references."}),"\n"]}),"\n",(0,l.jsx)(n.h3,{id:"major-collection",children:"Major Collection"}),"\n",(0,l.jsxs)(n.ul,{children:["\n",(0,l.jsx)(n.li,{children:"JVM tries to predict, set % threshold and start collection when threshold is passed."}),"\n",(0,l.jsx)(n.li,{children:"When object cannot be promoted from younger gen due to lack of space in old gen, then FullGC is triggered."}),"\n",(0,l.jsx)(n.li,{children:"FullGC = minor collection + major collection (including compaction)."}),"\n",(0,l.jsx)(n.li,{children:"FullGC is also triggered when old gen size needs to be changed. This can be avoided by keeping Xms same as Xmx"}),"\n",(0,l.jsx)(n.li,{children:"Compaction is likely to cause largest STW"}),"\n"]}),"\n",(0,l.jsx)(n.h3,{id:"serial-collector",children:"Serial Collector"}),"\n",(0,l.jsxs)(n.ul,{children:["\n",(0,l.jsx)(n.li,{children:"Smallest footprint of any collectors"}),"\n",(0,l.jsx)(n.li,{children:"Uses single thread for both minor and major collections."}),"\n",(0,l.jsx)(n.li,{children:"Objects in old gen are allocated with simple bump the pointer technique"}),"\n",(0,l.jsx)(n.li,{children:"Major GC is triggered when old gen is full"}),"\n"]}),"\n",(0,l.jsx)(n.h3,{id:"parallel-collector",children:"Parallel Collector"}),"\n",(0,l.jsxs)(n.ul,{children:["\n",(0,l.jsx)(n.li,{children:"Parallel Collector - Multiple threads for minor GC, and single thread for major GC."}),"\n",(0,l.jsx)(n.li,{children:"Parallel Old Collector - Multiple threads for both minor and major GC. Default since Java 7u4"}),"\n",(0,l.jsx)(n.li,{children:"Doesn't run with the application."}),"\n",(0,l.jsx)(n.li,{children:"Greatest throughput in multi-processor systems. Great for batch applications."}),"\n",(0,l.jsx)(n.li,{children:"Cost of Old GC, is proportional to number of objects, thus doubling old gen size can help in increasing throughput (larger but fewer GC pauses)."}),"\n",(0,l.jsx)(n.li,{children:"Minor GCs are fast because promotion in old gen is just bump-the-pointer."}),"\n",(0,l.jsx)(n.li,{children:"Major GC takes 1-5 seconds per live data"}),"\n",(0,l.jsx)(n.li,{children:"Allows for -XX:+UseNUMA to allocate Eden space per CPU socket (can increase performance)"}),"\n"]}),"\n",(0,l.jsx)(n.h3,{id:"concurrent-mark-and-sweep",children:"Concurrent Mark and Sweep"}),"\n",(0,l.jsxs)(n.ul,{children:["\n",(0,l.jsx)(n.li,{children:"Parallel (multiple threads) for Minor GC"}),"\n",(0,l.jsx)(n.li,{children:"Runs with application to try to avoid promotion failure. Promotion failure causes FullGC."}),"\n",(0,l.jsxs)(n.li,{children:["CMS =","\n",(0,l.jsxs)(n.ul,{children:["\n",(0,l.jsx)(n.li,{children:"Initial mark = Find GC roots"}),"\n",(0,l.jsx)(n.li,{children:"Concurrent mark = mark all objects from GC root"}),"\n",(0,l.jsx)(n.li,{children:"Concurrent pre-clean = check for updated object references & promoted objects during mark (Card Marking technique)"}),"\n",(0,l.jsx)(n.li,{children:"Re-mark = mark all objects in pre-clean"}),"\n",(0,l.jsx)(n.li,{children:"Concurrent sweep = reclaim memory and update free-lists"}),"\n",(0,l.jsx)(n.li,{children:"Concurrent reset = reset data structures used"}),"\n"]}),"\n"]}),"\n",(0,l.jsx)(n.li,{children:"During concurrent sweep, promotions can occur, but those are in free-lists which are not being swept anyways. So there is not conflict."}),"\n",(0,l.jsx)(n.li,{children:"Minor GCs can keep happening while Major GC is happening! Thus the pre-clean phase."}),"\n",(0,l.jsx)(n.li,{children:"Slower minor GCs during promotion. Cost of promotion is higher since, free-lists have to be checked for suitable sized hole."}),"\n",(0,l.jsx)(n.li,{children:"CMS is not compacting collector, so when object promotion fails due to not having enough space in free-lists. CMS is followed by compaction. This latency can be worse than Parallel Old collector."}),"\n",(0,l.jsx)(n.li,{children:"Decreases latency, but less throughput. Avg \xbc GC threads per 1 CPU core."}),"\n",(0,l.jsx)(n.li,{children:"Throughput reduction between 20-40% compared to parallel collector (& based on object allocation rate)."}),"\n",(0,l.jsx)(n.li,{children:"20% more space required."}),"\n",(0,l.jsx)(n.li,{children:'"Concurrent mode failure" - When CMS cannot keep up with high promotion rates. Increasing heap makes it even worse, because sweeping will take even more time.'}),"\n"]}),"\n",(0,l.jsx)(n.h3,{id:"g1-garbage-first",children:(0,l.jsx)(n.a,{href:"https://www.youtube.com/watch?v=Gee7QfoY8ys",children:"G1 Garbage First"})}),"\n",(0,l.jsxs)(n.ul,{children:["\n",(0,l.jsx)(n.li,{children:"Soft real-time targets. Spend x milliseconds in GC out of y milliseconds."}),"\n",(0,l.jsx)(n.li,{children:"Divides heap into large regions ~2048"}),"\n",(0,l.jsx)(n.li,{children:"Categorizes regions in Eden, Survivor and Old gen spaces."}),"\n",(0,l.jsx)(n.li,{children:"Minor GC is triggered, when all Eden regions are filled."}),"\n",(0,l.jsx)(n.li,{children:"Selects closest set of nearly free regions (called Collection Set), to move live objects, essentially causing regions to be empty. Thus it approaches problem incrementally, as opposed to CMS which has to perform on entire Old gen."}),"\n",(0,l.jsx)(n.li,{children:'Objects larger than 50% of region are saved in "humungous region"'}),"\n",(0,l.jsx)(n.li,{children:"Regions can have objects being referenced from multiple other regions. These are tracked using Reference Sets. Thus, while moving live objects, all the references to such objects need to be updated. Thus, even minor collections can potentially be longer than Parallel or CMS collector."}),"\n",(0,l.jsx)(n.li,{children:"It avoids collecting (moving) from regions which have high references. Unless it has no other option."}),"\n",(0,l.jsxs)(n.li,{children:["G1 is target driven on latency \u2013XX",":MaxGCPauseMillis","=<n>, default value = 200ms"]}),"\n",(0,l.jsx)(n.li,{children:"G1 reduces worst case latency, at the cost of higher average latency."}),"\n",(0,l.jsx)(n.li,{children:"Compactions are piggybacked on Young Gen GC."}),"\n",(0,l.jsx)(n.li,{children:"During reference changes, cards (arrays pointing to 512 bytes of a region) are marked dirty, and source-target details are placed in dirty card queue. Depending on number of elements in queue (white, green, yellow, red) G1 starts threads which take information from queue and write to Remembered Set. More the queue is full, more G1 threads try to drain it. Remembered set will be heavily contended if all threads directly write to RS, its better if only specific G1 threads (1 or 2) write to them."}),"\n",(0,l.jsx)(n.li,{children:"If Young GC cannot finish within maxTargetPauseTime, then # of Eden regions are reduced to finish within the target."}),"\n",(0,l.jsx)(n.li,{children:"Old GC is triggered when total 45% is full, and is checked just after Young GC or after allocating humongous object."}),"\n"]}),"\n",(0,l.jsx)(n.h3,{id:"shenandoah",children:(0,l.jsx)(n.a,{href:"https://www.youtube.com/watch?v=N0JTvyCxiv8",children:"Shenandoah"})}),"\n",(0,l.jsxs)(n.ul,{children:["\n",(0,l.jsx)(n.li,{children:"10% hit in throughput, but 7x more responsive."}),"\n",(0,l.jsx)(n.li,{children:"Avg Pause 5x better - 60ms (vs 600ms in G1)."}),"\n",(0,l.jsx)(n.li,{children:"Max Pause 3x better - 500ms (vs 1700ms). Lot of headroom."}),"\n",(0,l.jsx)(n.li,{children:"Target - 10ms average, and max 100ms."}),"\n",(0,l.jsx)(n.li,{children:"Region based like G1 (remembered sets, collection sets)"}),"\n",(0,l.jsx)(n.li,{children:"Concurrent mark and sweep same as CMS and G1"}),"\n",(0,l.jsx)(n.li,{children:"It does compaction though + concurrently while threads are running"}),"\n",(0,l.jsx)(n.li,{children:"Trick is to create indirection pointer to objects, and after copying live objects, atomically update the indirection pointer to copied version of the objects."}),"\n",(0,l.jsx)(n.li,{children:"Not Generational. Claim is, Weak Generational Hypothesis is no longer applicable."}),"\n"]}),"\n",(0,l.jsx)(n.h3,{id:"other-pauses-not-related-to-gc",children:"Other pauses not related to GC"}),"\n",(0,l.jsxs)(n.ul,{children:["\n",(0,l.jsx)(n.li,{children:"Networking, Disk read/writes, Waiting for DBs"}),"\n",(0,l.jsx)(n.li,{children:"OS interrupts (~5ms), this doesn't show up in logs"}),"\n",(0,l.jsx)(n.li,{children:"Lock contention"}),"\n"]})]})}function h(e={}){const{wrapper:n}={...(0,t.R)(),...e.components};return n?(0,l.jsx)(n,{...e,children:(0,l.jsx)(d,{...e})}):d(e)}},8453:(e,n,i)=>{i.d(n,{R:()=>o,x:()=>s});var r=i(6540);const l={},t=r.createContext(l);function o(e){const n=r.useContext(t);return r.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function s(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(l):e.components||l:o(e.components),r.createElement(t.Provider,{value:n},e.children)}}}]);