"use strict";(self.webpackChunkalex_ilin_kb=self.webpackChunkalex_ilin_kb||[]).push([[9737],{3909:(e,n,o)=>{o.r(n),o.d(n,{assets:()=>l,contentTitle:()=>s,default:()=>h,frontMatter:()=>t,metadata:()=>c,toc:()=>a});var i=o(4848),r=o(8453);const t={},s="Kafka",c={id:"Development/Kafka/kafka",title:"Kafka",description:"Troubleshooting",source:"@site/docs/Development/Kafka/kafka.md",sourceDirName:"Development/Kafka",slug:"/Development/Kafka/",permalink:"/kb/Development/Kafka/",draft:!1,unlisted:!1,editUrl:"https://github.com/engilyin/kb/docs/Development/Kafka/kafka.md",tags:[],version:"current",lastUpdatedAt:1754240444e3,frontMatter:{},sidebar:"defaultSidebar",previous:{title:"Kafka",permalink:"/kb/category/kafka"},next:{title:".Net",permalink:"/kb/Development/Other/dotnet"}},l={},a=[{value:"Troubleshooting",id:"troubleshooting",level:2},{value:"Kerberos",id:"kerberos",level:3},{value:"Theory",id:"theory",level:2},{value:"producer",id:"producer",level:3},{value:"CLI commands",id:"cli-commands",level:2},{value:"producer",id:"producer-1",level:3},{value:"consumer",id:"consumer",level:3},{value:"Tune up",id:"tune-up",level:2},{value:"Performance",id:"performance",level:3},{value:"Segments",id:"segments",level:3},{value:"Cleanup policy",id:"cleanup-policy",level:3},{value:"Networking",id:"networking",level:3},{value:"compact",id:"compact",level:3},{value:"Compression",id:"compression",level:3},{value:"Broker Configuration:",id:"broker-configuration",level:3},{value:"Producer Configuration:",id:"producer-configuration",level:3},{value:"Consumer Configuration:",id:"consumer-configuration",level:3},{value:"Topic Configuration:",id:"topic-configuration",level:3},{value:"Commit Strategy",id:"commit-strategy",level:2},{value:"Windows",id:"windows",level:2}];function d(e){const n={code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",ol:"ol",p:"p",pre:"pre",ul:"ul",...(0,r.R)(),...e.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(n.header,{children:(0,i.jsx)(n.h1,{id:"kafka",children:"Kafka"})}),"\n",(0,i.jsx)(n.h2,{id:"troubleshooting",children:"Troubleshooting"}),"\n",(0,i.jsx)(n.h3,{id:"kerberos",children:"Kerberos"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{children:"-Dsun.security.krb5.debug=true\n"})}),"\n",(0,i.jsx)(n.h2,{id:"theory",children:"Theory"}),"\n",(0,i.jsx)(n.p,{children:"ISR (In-Sync Replica) - replica partition received from the Leader partition"}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.code,{children:"at least once"})," - commit after message has been processed. Can result duplicate prcessing. So we need indepotent consumer.\n",(0,i.jsx)(n.code,{children:"at most once"})," - commit when message has been received. If it fail we never process it again.\n",(0,i.jsx)(n.code,{children:"exactly once"})," - guaranty once processing. Either Transactional API (for Kafka to Kafka). Or Indepotent Consumer"]}),"\n",(0,i.jsx)(n.h3,{id:"producer",children:"producer"}),"\n",(0,i.jsx)(n.p,{children:"Acknolegemnt Strategy\nacks=0 do not wait for acknolegment (possible data loss)\nacks=1 wait from leader (limited data loss)\nacks=all wait for all replicas will acknoledge (no data loss)"}),"\n",(0,i.jsx)(n.h2,{id:"cli-commands",children:"CLI commands"}),"\n",(0,i.jsx)(n.p,{children:"Create new topic"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{children:"kafka-topics --create --bootstrap-server localhost:9092 --topic my-topic --replication-factor 1 --partitions 3 \n\nkafka-topics --create --bootstrap-server localhost:9092 --topic my-topic --replication-factor 1 --partitions 3 \\\n      --config cleanup.policy=compact \\\n      --config min.cleanup.dirty.ratio=0.001 \\\n      --config segments.ms=5000\n"})}),"\n",(0,i.jsx)(n.p,{children:"Describe topic"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{children:"kafka-topics --bootstrap-server localhost:9092 --topic my-topic --describe\n"})}),"\n",(0,i.jsx)(n.p,{children:"Get kafka config params:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{children:"kafka-configs\n"})}),"\n",(0,i.jsx)(n.p,{children:"Configure topic"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{children:"kafka-configs --bootstrap-server localhost:9092 --entity-type topics --entity-name my-topic --describe\nkafka-configs --bootstrap-server localhost:9092 --entity-type topics --entity-name my-topic --alter --add-config min.insync.replicas=2\nkafka-configs --bootstrap-server localhost:9092 --entity-type topics --entity-name my-topic --alter --delete-config min.insync.replicas\n"})}),"\n",(0,i.jsx)(n.h3,{id:"producer-1",children:"producer"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{children:"kafka-console-producer --bootstrap-server localhost:9092 --topic my-topic \\\n            --property parse.key=true \\\n            --property key.separator=,\n"})}),"\n",(0,i.jsx)(n.h3,{id:"consumer",children:"consumer"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{children:"kafka-console-consumer --bootstrap-server localhost:9092 --topic my-topic \\\n            --from-beginning \\\n            --property print.key=true \\\n            --property key.separator=,\n\n"})}),"\n",(0,i.jsx)(n.h2,{id:"tune-up",children:"Tune up"}),"\n",(0,i.jsx)(n.h3,{id:"performance",children:"Performance"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"latency"}),"\n",(0,i.jsx)(n.li,{children:"throughput"}),"\n",(0,i.jsx)(n.li,{children:"durability"}),"\n",(0,i.jsx)(n.li,{children:"availability"}),"\n"]}),"\n",(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsx)(n.li,{children:"Smart batching helps to increase troughput while maintaining very low latency"}),"\n"]}),"\n",(0,i.jsxs)(n.p,{children:["Producers tries to send record asap. It will have up to ",(0,i.jsx)(n.code,{children:"max.in.flight.requests.per.connection=5"}),"\nWhich means max 5 message batches being in flight (being sent between the producer and broker)"]}),"\n",(0,i.jsx)(n.p,{children:"If more messages are coming while others in flight Kafka batch it."}),"\n",(0,i.jsxs)(n.ol,{start:"2",children:["\n",(0,i.jsx)(n.li,{children:"Compression"}),"\n"]}),"\n",(0,i.jsx)(n.p,{children:"more batching - more efficient Compression."}),"\n",(0,i.jsx)(n.p,{children:"Use producer level compression"}),"\n",(0,i.jsxs)(n.ol,{start:"3",children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.code,{children:"linger.ms"})," (default 0) and ",(0,i.jsx)(n.code,{children:"batch.size"})," (default 16Kb)"]}),"\n"]}),"\n",(0,i.jsx)(n.p,{children:"How long to wait before send the batch. Helps to get bigger batches and send more at once in expence of latency."}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.code,{children:"batch.size"})," force batch sending before ",(0,i.jsx)(n.code,{children:"linger.ms"})]}),"\n",(0,i.jsx)(n.h3,{id:"segments",children:"Segments"}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.code,{children:"log.segment.bytes"})," - max size of a single segment in bytes (default 1Gb)\n",(0,i.jsx)(n.code,{children:"log.segment.ms"})," the time Kafka will wait before commiting the segment if not full (default 1 week)"]}),"\n",(0,i.jsx)(n.p,{children:"Smaller segments: often log compactions and more opened files"}),"\n",(0,i.jsx)(n.p,{children:"You may consider more segments if you have low throughput so compaction get more offen."}),"\n",(0,i.jsx)(n.h3,{id:"cleanup-policy",children:"Cleanup policy"}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.code,{children:"log.cleanup.policy"})," could be ",(0,i.jsx)(n.code,{children:"delete"})," (based on age, week is default or size. default infinite), ",(0,i.jsx)(n.code,{children:"compact"})," (use latest key)"]}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.code,{children:"log.retntion.hours"})," number of hours to keep data (default 168 - one week) also ",(0,i.jsx)(n.code,{children:"log.retntion.minutes"}),", ",(0,i.jsx)(n.code,{children:"log.retntion.ms"})," (milliseconds) -1 means infinit"]}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.code,{children:"log.retention.bytes"})," - max size in bytes for each partition size (default -1 infinit)"]}),"\n",(0,i.jsx)(n.h3,{id:"networking",children:"Networking"}),"\n",(0,i.jsx)(n.p,{children:"Rack awarnes: Kafka Consumers Replica Fetching (since 2.4+). To improve latency and decrise network costs:"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:["for the broker:","\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:["set ",(0,i.jsx)(n.code,{children:"rack.id"})]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.code,{children:"replicka.selector.class"})," = ",(0,i.jsx)(n.code,{children:"org.apache.kafka.common.replica.RackAwareReplicaSelector"})]}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["for  client:","\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:(0,i.jsx)(n.code,{children:"client.rack"})}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,i.jsx)(n.h3,{id:"compact",children:"compact"}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.code,{children:"delete.retention.ms"})," (default 24 hrs) how long consumer can see deleted records"]}),"\n",(0,i.jsx)(n.h3,{id:"compression",children:"Compression"}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.code,{children:"none"}),", ",(0,i.jsx)(n.code,{children:"gzip"}),", ",(0,i.jsx)(n.code,{children:"snappy"}),", ",(0,i.jsx)(n.code,{children:"lz4"}),", ",(0,i.jsx)(n.code,{children:"zstd"})]}),"\n",(0,i.jsx)(n.h3,{id:"broker-configuration",children:"Broker Configuration:"}),"\n",(0,i.jsxs)(n.p,{children:["Adjust ",(0,i.jsx)(n.code,{children:"num.partitions"})," and ",(0,i.jsx)(n.code,{children:"default.replication.factor"})," based on your workload and redundancy requirements.\nTune ",(0,i.jsx)(n.code,{children:"log.segment.bytes"})," and ",(0,i.jsx)(n.code,{children:"log.segment.ms"})," to control the size and frequency of log segment rolling.\nSet appropriate values for ",(0,i.jsx)(n.code,{children:"num.io.threads"}),", ",(0,i.jsx)(n.code,{children:"num.network.threads"}),", ",(0,i.jsx)(n.code,{children:"socket.receive.buffer.bytes"}),", and ",(0,i.jsx)(n.code,{children:"socket.request.max.bytes"})," based on your hardware and workload."]}),"\n",(0,i.jsx)(n.h3,{id:"producer-configuration",children:"Producer Configuration:"}),"\n",(0,i.jsxs)(n.p,{children:["Configure ",(0,i.jsx)(n.code,{children:"batch.size"}),", ",(0,i.jsx)(n.code,{children:"linger.ms"}),", and compression.type to optimize producer throughput and latency.\nSet ",(0,i.jsx)(n.code,{children:"max.in.flight.requests.per.connection"})," to balance between throughput and reliability.\nAdjust acks to control the durability guarantee provided by Kafka."]}),"\n",(0,i.jsx)(n.h3,{id:"consumer-configuration",children:"Consumer Configuration:"}),"\n",(0,i.jsxs)(n.p,{children:["Tune ",(0,i.jsx)(n.code,{children:"fetch.min.bytes"}),", ",(0,i.jsx)(n.code,{children:"fetch.max.wait.ms"}),", and ",(0,i.jsx)(n.code,{children:"max.poll.records"})," to balance between latency and throughput.\nSet appropriate values for ",(0,i.jsx)(n.code,{children:"enable.auto.commit"}),", ",(0,i.jsx)(n.code,{children:"auto.commit.interval.ms"}),", and ",(0,i.jsx)(n.code,{children:"auto.offset.reset"})," (earliest|latest| or error for other vals) based on your application's requirements.\nUse consumer groups efficiently to parallelize processing."]}),"\n",(0,i.jsx)(n.h3,{id:"topic-configuration",children:"Topic Configuration:"}),"\n",(0,i.jsxs)(n.p,{children:["Configure retention policies (",(0,i.jsx)(n.code,{children:"retention.ms"}),", ",(0,i.jsx)(n.code,{children:"retention.bytes"}),") based on your data retention requirements.\nAdjust ",(0,i.jsx)(n.code,{children:"cleanup.policy"})," to control log retention and deletion strategy.\nSet ",(0,i.jsx)(n.code,{children:"segment.bytes"})," and ",(0,i.jsx)(n.code,{children:"segment.ms"})," to optimize log segment rolling."]}),"\n",(0,i.jsx)(n.h2,{id:"commit-strategy",children:"Commit Strategy"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Auto offset commit behavior"}),"\n"]}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.code,{children:"auto.commit.interval.ms=5000"})," ",(0,i.jsx)(n.code,{children:"enable.auto.commit=true"})]}),"\n",(0,i.jsx)(n.p,{children:"For Kafka Streams\nprops.put(StreamsConfig.PROCESSING_GUARANTEE_CONFIG, StreamsConfig.AT_MOST_ONCE);"}),"\n",(0,i.jsx)(n.p,{children:"props.put(StreamsConfig.NUM_STREAM_THREADS_CONFIG, 4); // Set the number of stream threads to 4"}),"\n",(0,i.jsx)(n.h2,{id:"windows",children:"Windows"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Sliding"}),"\n",(0,i.jsx)(n.li,{children:"Tumbling"}),"\n",(0,i.jsx)(n.li,{children:"Hopping"}),"\n",(0,i.jsx)(n.li,{children:"Session"}),"\n"]})]})}function h(e={}){const{wrapper:n}={...(0,r.R)(),...e.components};return n?(0,i.jsx)(n,{...e,children:(0,i.jsx)(d,{...e})}):d(e)}},8453:(e,n,o)=>{o.d(n,{R:()=>s,x:()=>c});var i=o(6540);const r={},t=i.createContext(r);function s(e){const n=i.useContext(t);return i.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function c(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:s(e.components),i.createElement(t.Provider,{value:n},e.children)}}}]);